
# ğŸ–ï¸ Face + Hand Gesture Controlled Device

## ğŸ“˜ Project Report

**Main Project**: Object Detection and Classification  
**Subproject**: Hand Gesture Controller

---

## ğŸ§© Problem Statement

Traditional input devices like mouse and keyboard are not always practical or accessible. There's a growing demand for **touchless interaction**, especially:

- In post-COVID environments for hygiene
- For people with physical disabilities
- During teaching or presentations
- On systems without a touchpad (e.g., Raspberry Pi)

---

## ğŸ“ What We Learned

- **Linear Regression** with Gradient Descent
- **Regularization** to prevent overfitting
- **Neural Networks**: ANN & CNN
- **Backpropagation**, Activation Functions: ReLU, Sigmoid
- **PyTorch** framework
- **Data Augmentation** for improving datasets
- **YOLO** training for real-time object detection
- Working with **Roboflow** & custom datasets
- Using **OpenCV** for webcam integration
- Working with **LLMs** and **Agentic AI**

---

## ğŸ› ï¸ Tools & Technologies Used

| Tool / Library        | Purpose                                |
|-----------------------|-----------------------------------------|
| Python                | Programming Language                    |
| FaceNet               | Face Recognition (InceptionResnetV1)    |
| OpenCV                | Video capture & processing              |
| MediaPipe             | Hand & Face landmark detection          |
| PyAutoGUI             | Mouse, Keyboard, Scroll, Volume Control |
| NumPy                 | Distance, Interpolation                 |
| Webcam                | Real-time input                         |

---

## ğŸ§  Project Architecture

```text
[ Webcam Frame (cv2) ]
         â”‚
         â–¼
[ Face Detection (MediaPipe) ]
         â”‚
         â”œâ”€â–º Crop Face
         â”‚     â–¼
         â”‚ [ InceptionResnetV1 (FaceNet) â†’ 512D Embedding ]
         â”‚     â–¼
         â”‚ [ Compare with Saved Embeddings â†’ Identity ]
         â””â”€â”€â”€â”€â–º If identity == "punit" â†’ Allow gesture control

         â–¼
[ Hand Detection (MediaPipe Hands) ]
         â–¼
[ Landmark Extraction & Gesture Analysis (Custom logic) ]
         â–¼
[ Action Execution (pyautogui) ]
      - Mouse control
      - Zoom
      - Volume
      - Scroll
      - Double Click
```

---

## ğŸŒ Real-World Applications

- ğŸ  **Smart Home**: Gesture control for lights, fans, media  
- ğŸ§‘â€ğŸ’» **Touchless Computers**: For accessibility or hygiene  
- ğŸš— **Vehicles**: Adjust volume/calls with gestures  
- ğŸ« **Classrooms**: Gesture-based slide/presentation control  
- ğŸ¥ **Hospitals**: Surgeons interact without touching surfaces  
- ğŸ” **Secure Kiosks**: Face unlock + gesture navigation  
- ğŸ•¶ï¸ **AR/VR Interfaces**: Natural control in immersive apps  
- ğŸ“¹ **Surveillance**: Allow only known users to control panels  
- ğŸ­ **Industrial Monitoring**: Gesture dashboard navigation  
- ğŸ“± **Mobile Apps**: Gesture-based controls using webcam

---

## âš ï¸ Challenges Faced

| # | Issue                         | Cause                                                   | Fix                                                                 |
|---|-------------------------------|----------------------------------------------------------|----------------------------------------------------------------------|
| 1 | ğŸ•’ Slow Response Time         | Model inference, frame lag                              | Reduce resolution, optimize cooldown, consider threading            |
| 2 | ğŸ–± Double Click Unreliable     | Gesture held too short/long                             | Use stable gestures (e.g. two-tap), improve timing logic            |
| 3 | ğŸ” Too Many Actions Triggering| Multiple gesture matches                                | Use gesture priority or modes                                       |
| 4 | ğŸ“œ Scroll Didnâ€™t Work Properly| Finger Y-position inconsistent                          | Widen Y-thresholds or use gesture speed                             |
| 5 | ğŸ” Zoom In/Out Glitches       | Unstable distance thresholds                            | Smooth distance with averaging, adjust thresholds                   |
| 6 | âš¡ Fast Start, Then Delay     | Cooldown blocks rapid repeated gestures                 | Refine cooldown logic, detect gesture *change*, not just time-based |

---

## ğŸ”® Future Work

- ğŸ“º Integration with **Smart Home Devices**
- ğŸ“ Deployment on **Raspberry Pi**
- âœŒï¸ **Multi-hand & Multi-user Support**
- ğŸ—£ï¸ **Voice + Gesture Hybrid Control**
- ğŸ§  **Gesture Customization**
- ğŸŒ Expand to **Mobile, Smart TVs, AR/VR, IoT**

---

## ğŸ“¦ requirements.txt

```txt
opencv-python
mediapipe
pyautogui
numpy
torch
facenet-pytorch
```

---

## âœ… How to Use

1. Clone this repository  
2. Run `pip install -r requirements.txt`  
3. Place your face embedding files (`*.pt`) in the same folder  
4. Run the main Python script  
5. Use gestures after face recognition (Punit is authenticated)

---

